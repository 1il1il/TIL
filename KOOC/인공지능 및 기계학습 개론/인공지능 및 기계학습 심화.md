## [인공지능 및 기계학습 심화](https://kaist.edwith.org/aiml-adv#)

## Week 1

### Dirichlet Process: Gaussian Mixture Model and Dirichlet Distribution Review

- Gaussian Mixture Model
- Dirichlet Distribution
  - GMM의 z: multinomial dist의 choice size varying(parameter 생성 방법) > Dirichlet dist 사용

### Dirichlet Process: Multinomial-Dirichlet Conjugate Relation

- Multinomial distribution
  - P(D|θ)
- Dirichlet distribution
  - P(θ|a)
- Bayesian Posterior
  - P(θ|D, a) ∝ P(D|θ) P(θ|a)
- Coming back to the Dirichlet distribution : Conjugate Prior
  - The likeilhood of the Dirichlet distribution is the conjugate prior of the multinomial distribution
- Dirichlet distribution with D as a single observation with i-th choice
  - θ|a ~ Dir(a1, ..., ai, ..., an)
  - θ|a, D ~ Dir(a1, ..., ai+1, ..., an)
  - 데이터가 관측되어 파라메터가 변화하게되었다

### Dirichlet Process: Definition

- Dirichlet Process, G|a,H ~ DP(a, H)

  - (G(A1), ..., G(Ar)) | a, H ~ Dir(aH(A1), ..., aH(Ar))
    - A1 ∩ ... ∩ Ar = 공집합,  A1 ∪ ... ∪ Ar = 전체집합
    - Dirichlet distribution의 parameter에 PDF 확률 분포를 가미
    - 이 결과(G(A1), ..., G(Ar))는 Multinomial distribution의 parameter를 만들어 내는 것, 선택지의 확률, Prior
  - Properties
    - E[G(A)] = H(A)
    - V[G(A)] = H(A)(1-H(A)) / a + 1
    - H : Base distribution
    - a : Concentration parameter, strength parameter (strength of prior)
- Posterior distribution given a dataset of θ1 ... θn

  - Posterior ∝ Likelihood X Prior
  - Multinomial-Dirichlet conjugate eelationship
    - The posterior become the Dirichlet distribution, again, adjusted to reflect the likelihood
  - (G(A1), ..., G(Ar)) | θ1 ... θn, a, H ~ Dir(aH(A1), ..., aH(Ar)+ nr)
    - nk = |{θi|θi ∈ Ak, 1 ≤ i ≤ n}|
      - θi:특정한 영역에 속하는지 속하지 않는지
    - n번의 trial이 있고 이때마다 특정한 선택지를 선택, 이벤트가 발생
- Sampling from Dirichlet Process
  - Multiple generation schemes, or construction, exist
    - Stick Breaking Scheme
    - Polya Urn Scheme
    - Chinese Restaurant Process Scheme