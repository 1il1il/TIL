{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-conversion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# train, validation TFRecord 파일 경로\n",
    "train_tfrecord_path = '../data/cat_dog/cat_dog_train.tfrecords'\n",
    "valid_tfrecord_path = '../data/cat_dog/cat_dog_valid.tfrecords'\n",
    "\n",
    "BUFFER_SIZE = 256     # 데이터 shuffle을 위한 buffer size\n",
    "BATCH_SIZE = 20       # 배치 사이즈. 한번에 가져오는 이미지 데이터 개수 \n",
    "NUM_CLASS = 2         # class의 개수. binary인 경우는 필요없으며 categorical인 경우 설정\n",
    "IMAGE_SIZE = 150       \n",
    "\n",
    "\n",
    "# TFRecord를 읽어서 데이터를 복원하기 위한 자료구조.\n",
    "image_feature_description = {\n",
    "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'id': tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "\n",
    "# 읽어들인 TFRecord를 다음의 형태(dict)로 변환하는 함수\n",
    "def _parse_image_function(example_proto):\n",
    "    return tf.io.parse_single_example(example_proto, \n",
    "                                      image_feature_description)\n",
    "\n",
    "# 위에서 얻은 ParallelMapDataset를 다음의 형태(shape)로 변환하는 함수\n",
    "def map_func(target_record):\n",
    "    img = target_record['image_raw']\n",
    "    label = target_record['label']\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.dtypes.cast(img, tf.float32)\n",
    "    return img, label\n",
    "\n",
    "\n",
    "# 전처리(resize & augmentation) 함수\n",
    "def image_resize_func(image, label):\n",
    "    # result_image = image / 255\n",
    "    result_image = tf.image.resize(image, (IMAGE_SIZE,IMAGE_SIZE))   \n",
    "    return result_image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-relay",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.TFRecordDataset(train_tfrecord_path, \n",
    "                                  compression_type='GZIP')\n",
    "train_dataset = train_dataset.map(_parse_image_function, \n",
    "                      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "train_dataset = train_dataset.map(map_func, \n",
    "                      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "train_dataset = train_dataset.cache()\n",
    "# dataset shuffle 처리\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
    "\n",
    "# 전처리(resize & auigmentation)\n",
    "train_dataset = train_dataset.map(image_resize_func, \n",
    "                      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# BatchDataset으로 변환\n",
    "# <BatchDataset shapes: ((None, None, None, 3), (None,)), types: (tf.float32, tf.int64)>\n",
    "# BatchDataset으로 변환하기 전에 image의 resize(전처리)가 일어나야 한다. 그렇지 않으면 \n",
    "# shape이 달라 batch처리가 되지 않는다는 오류 발생.\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "# prefetch처리\n",
    "# prefetch는 전처리와 학습과정의 모델 실행을 오버랩.\n",
    "# 모델이 s스텝 학습을 실행하는 동안 입력 파이프라인은 s+1스텝의 데이터를 읽어서 수행속도를 높임.\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-trick",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = tf.data.TFRecordDataset(valid_tfrecord_path, \n",
    "                                  compression_type='GZIP')\n",
    "valid_dataset = valid_dataset.map(_parse_image_function, \n",
    "                      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "valid_dataset = valid_dataset.map(map_func, \n",
    "                      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "valid_dataset = valid_dataset.cache()\n",
    "# dataset shuffle 처리\n",
    "valid_dataset = valid_dataset.shuffle(BUFFER_SIZE)\n",
    "\n",
    "# 전처리(resize & auigmentation)\n",
    "valid_dataset = valid_dataset.map(image_resize_func, \n",
    "                      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# BatchDataset으로 변환\n",
    "# <BatchDataset shapes: ((None, None, None, 3), (None,)), types: (tf.float32, tf.int64)>\n",
    "# BatchDataset으로 변환하기 전에 image의 resize(전처리)가 일어나야 한다. 그렇지 않으면 \n",
    "# shape이 달라 batch처리가 되지 않는다는 오류 발생.\n",
    "valid_dataset = valid_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "# prefetch처리\n",
    "# prefetch는 전처리와 학습과정의 모델 실행을 오버랩.\n",
    "# 모델이 s스텝 학습을 실행하는 동안 입력 파이프라인은 s+1스텝의 데이터를 읽어서 수행속도를 높임.\n",
    "valid_dataset = valid_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artistic-going",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), \n",
    "                 activation='relu', input_shape=(150,150,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), \n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), \n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), \n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=512, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-3), \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "growing-farming",
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps_per_epoch : 몇번 뽑아야 1 epoch이 되는가\n",
    "history = model.fit(train_dataset, steps_per_epoch=800, epochs=30,\n",
    "                    validation_data=valid_dataset,\n",
    "                    validation_steps=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_env_tf2] *",
   "language": "python",
   "name": "conda-env-data_env_tf2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
