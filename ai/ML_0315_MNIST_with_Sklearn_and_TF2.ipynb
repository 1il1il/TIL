{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST, Sklearn, Tensorflow 2.x으로 구현\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn result : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1242\n",
      "           1       0.95      0.97      0.96      1429\n",
      "           2       0.92      0.90      0.91      1276\n",
      "           3       0.91      0.90      0.90      1298\n",
      "           4       0.92      0.92      0.92      1236\n",
      "           5       0.88      0.88      0.88      1119\n",
      "           6       0.93      0.96      0.94      1243\n",
      "           7       0.94      0.93      0.94      1334\n",
      "           8       0.89      0.88      0.88      1204\n",
      "           9       0.89      0.89      0.89      1219\n",
      "\n",
      "    accuracy                           0.92     12600\n",
      "   macro avg       0.92      0.92      0.92     12600\n",
      "weighted avg       0.92      0.92      0.92     12600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Raw Data Loading\n",
    "df = pd.read_csv('../data/digit-recognizer/train.csv')\n",
    "\n",
    "# 결측치와 이상치를 처리해야함\n",
    "# feature engineering - 학습에 필요없는 column을 삭제, \n",
    "# 기존 column을 이용해서 새로운 column을 생성\n",
    "# Binning 처리 (연속적인 숫자값을 categorical value로 변환)\n",
    "\n",
    "# 독립변수와 종속변수 분리\n",
    "x_data = df.drop('label', axis=1, inplace=False)\n",
    "t_data = df['label']\n",
    "\n",
    "# 정규화\n",
    "scaler = MinMaxScaler()\n",
    "# df넣으면 알아서 ndarray로 변환하여 사용\n",
    "scaler.fit(x_data)\n",
    "x_data_norm = scaler.transform(x_data)\n",
    "\n",
    "# Data Split\n",
    "x_data_train, x_data_test, t_data_train, t_data_test = \\\n",
    "train_test_split(x_data_norm, t_data, test_size=0.3, random_state=0)\n",
    "\n",
    "# Sklearn 구현\n",
    "\n",
    "# LogisticRegression은 solver를 지정해야 한다\n",
    "# 어떠한 형태로 모델을 만들것인지 (상대적으로 데이터의 크기 유무 - 많고, 적고)\n",
    "# default인 lbfgs는 작은 데이터에 최적화 > 데이터가 많으면 성능이 떨어진다\n",
    "# 현재 4만개의 데이터가 있기 때문에 작은 데이터는 아니다 \n",
    "# 일반적으로 데이터량이 많은 경우는 saga를 이용\n",
    "# sag > Stochastic Average Gradient Descent , saga는 sag의 확장판\n",
    "sklearn_model = LogisticRegression(solver='saga')\n",
    "sklearn_model.fit(x_data_train, t_data_train)\n",
    "print('sklearn result : ')\n",
    "print(classification_report(t_data_test, sklearn_model.predict(x_data_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow 2.x 구현\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394/394 [==============================] - 0s 409us/step - loss: 0.2963 - sparse_categorical_accuracy: 0.9171\n",
      "[0.2962534427642822, 0.9171428680419922]\n"
     ]
    }
   ],
   "source": [
    "# Raw Data Loading\n",
    "df = pd.read_csv('../data/digit-recognizer/train.csv')\n",
    "\n",
    "# 독립변수와 종속변수 분리\n",
    "x_data = df.drop('label', axis=1, inplace=False)\n",
    "t_data = df['label']\n",
    "# TF 1.x에선 one-hot해야함\n",
    "# TF 2.x에선 설정만 하면 one-hot처리를 안해도 됨\n",
    "\n",
    "# 정규화\n",
    "scaler = MinMaxScaler()\n",
    "# df넣으면 알아서 ndarray로 변환하여 사용\n",
    "scaler.fit(x_data)\n",
    "x_data_norm = scaler.transform(x_data)\n",
    "\n",
    "# Data Split\n",
    "x_data_train, x_data_test, t_data_train, t_data_test = \\\n",
    "train_test_split(x_data_norm, t_data, test_size=0.3, random_state=0)\n",
    "\n",
    "# Tensorflow 2.x\n",
    "keras_model = Sequential()\n",
    "keras_model.add(Flatten(input_shape=(x_data_train.shape[1],)))\n",
    "keras_model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# one-hot을 사용하지 않은 경우 sparse_categorical_crossentropy\n",
    "keras_model.compile(optimizer=SGD(learning_rate=1e-1), \n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "# 추후에 history를 이용해서 조절\n",
    "# verbose는 출력 옵션, 어떠한 내용을 출력할 것인가\n",
    "history = keras_model.fit(x_data_train, t_data_train, \n",
    "                          epochs=100, batch_size=512, verbose=0, \n",
    "                          validation_split=0.2)\n",
    "\n",
    "print(keras_model.evaluate(x_data_test, t_data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['loss', 'sparse_categorical_accuracy', 'val_loss', 'val_sparse_categorical_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# history객체 내에 history라는 속성이 있다 > dict\n",
    "print(type(history.history))\n",
    "# epoch당 각 key값에 대한 정보가 담겨있다\n",
    "print(history.history.keys())\n",
    "\n",
    "# epoch당 training data를 이용한 sparse_categorical_accuracy\n",
    "plt.plot(history.history['sparse_categorical_accuracy'], color='r')\n",
    "\n",
    "# epoch당 validation data를 이용한 val_sparse_categorical_accuracy\n",
    "plt.plot(history.history['val_sparse_categorical_accuracy'], color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\LiO\\anaconda3\\envs\\data_env_tf2\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression(Perceptron)\n",
    "# And, OR Gate를 학습시켜서 Prediction을 할 수 있는가?\n",
    "# Tensorflow 1.15를 이용해서 학습\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "from sklearn.metrics import classification_report\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- And Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainin Data Set\n",
    "x_data = np.array([[0,0], [0,1], [1,0], [1,1]], dtype=np.float32)\n",
    "\n",
    "# AND t_data\n",
    "t_data = np.array([[0], [0], [0], [1]], dtype=np.float32)\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None, 2], dtype=tf.float32)\n",
    "T = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "\n",
    "# W & b\n",
    "W = tf.Variable(tf.random.normal([2,1]))\n",
    "b = tf.Variable(tf.random.normal([1]))\n",
    "\n",
    "# Hypothesis\n",
    "logit = tf.matmul(X, W) + b\n",
    "H = tf.sigmoid(logit)\n",
    "\n",
    "# loss function\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit, \n",
    "                                                              labels=T))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-2).minimize(loss)\n",
    "\n",
    "# Session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 1.0008327960968018\n",
      "loss : 0.334287166595459\n",
      "loss : 0.2172527015209198\n",
      "loss : 0.1624193787574768\n",
      "loss : 0.1296493262052536\n",
      "loss : 0.10770364105701447\n",
      "loss : 0.09196663647890091\n",
      "loss : 0.0801398754119873\n",
      "loss : 0.07093765586614609\n",
      "loss : 0.06358186900615692\n"
     ]
    }
   ],
   "source": [
    "for step in range(30000):\n",
    "    _, loss_val = sess.run([train, loss], feed_dict={X : x_data, T: t_data})\n",
    "    \n",
    "    if step % 3000 == 0:\n",
    "        print('loss : {}'.format(loss_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "accuracy = tf.cast(H >= 0.5, dtype=tf.float32)\n",
    "\n",
    "result = sess.run(accuracy, feed_dict={X: x_data})\n",
    "print(classification_report(t_data, result.ravel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- OR Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainin Data Set\n",
    "x_data = np.array([[0,0], [0,1], [1,0], [1,1]], dtype=np.float32)\n",
    "\n",
    "# OR t_data\n",
    "t_data = np.array([[0], [1], [1], [1]], dtype=np.float32)\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None, 2], dtype=tf.float32)\n",
    "T = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "\n",
    "# W & b\n",
    "W = tf.Variable(tf.random.normal([2,1]))\n",
    "b = tf.Variable(tf.random.normal([1]))\n",
    "\n",
    "# Hypothesis\n",
    "logit = tf.matmul(X, W) + b\n",
    "H = tf.sigmoid(logit)\n",
    "\n",
    "# loss function\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit, \n",
    "                                                              labels=T))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-2).minimize(loss)\n",
    "\n",
    "# Session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.41868582367897034\n",
      "loss : 0.20556461811065674\n",
      "loss : 0.13196562230587006\n",
      "loss : 0.09587672352790833\n",
      "loss : 0.0747547447681427\n",
      "loss : 0.06101207807660103\n",
      "loss : 0.0514104887843132\n",
      "loss : 0.04434897378087044\n",
      "loss : 0.03895070403814316\n",
      "loss : 0.03469713777303696\n"
     ]
    }
   ],
   "source": [
    "for step in range(30000):\n",
    "    _, loss_val = sess.run([train, loss], feed_dict={X : x_data, T: t_data})\n",
    "    \n",
    "    if step % 3000 == 0:\n",
    "        print('loss : {}'.format(loss_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         1\n",
      "         1.0       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "accuracy = tf.cast(H >= 0.5, dtype=tf.float32)\n",
    "\n",
    "result = sess.run(accuracy, feed_dict={X: x_data})\n",
    "print(classification_report(t_data, result.ravel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- XOR Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainin Data Set\n",
    "x_data = np.array([[0,0], [0,1], [1,0], [1,1]], dtype=np.float32)\n",
    "\n",
    "# XOR t_data\n",
    "t_data = np.array([[0], [1], [1], [0]], dtype=np.float32)\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None, 2], dtype=tf.float32)\n",
    "T = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "\n",
    "# W & b\n",
    "W = tf.Variable(tf.random.normal([2,1]))\n",
    "b = tf.Variable(tf.random.normal([1]))\n",
    "\n",
    "# Hypothesis\n",
    "logit = tf.matmul(X, W) + b\n",
    "H = tf.sigmoid(logit)\n",
    "\n",
    "# loss function\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit, \n",
    "                                                              labels=T))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-2).minimize(loss)\n",
    "\n",
    "# Session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.7997751832008362\n",
      "loss : 0.7003811597824097\n",
      "loss : 0.6938228607177734\n",
      "loss : 0.6932108998298645\n",
      "loss : 0.6931532025337219\n",
      "loss : 0.6931477189064026\n",
      "loss : 0.6931472420692444\n",
      "loss : 0.6931471824645996\n",
      "loss : 0.6931471824645996\n",
      "loss : 0.6931471824645996\n"
     ]
    }
   ],
   "source": [
    "for step in range(30000):\n",
    "    _, loss_val = sess.run([train, loss], feed_dict={X : x_data, T: t_data})\n",
    "    \n",
    "    if step % 3000 == 0:\n",
    "        print('loss : {}'.format(loss_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.50      0.67         2\n",
      "         1.0       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.75         4\n",
      "   macro avg       0.83      0.75      0.73         4\n",
      "weighted avg       0.83      0.75      0.73         4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "accuracy = tf.cast(H >= 0.5, dtype=tf.float32)\n",
    "\n",
    "result = sess.run(accuracy, feed_dict={X: x_data})\n",
    "print(classification_report(t_data, result.ravel()))\n",
    "\n",
    "# XOR는 구현할 수 없다\n",
    "# 어떻게 구현해야 하는가?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_env_tf2]",
   "language": "python",
   "name": "conda-env-data_env_tf2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
