{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow 1.15 XOR Gate 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "from sklearn.metrics import classification_report\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data Set\n",
    "x_data = np.array([[0,0], [0,1], [1,0], [1,1]], dtype=np.float32)\n",
    "t_data = np.array([[0], [1], [1], [0]], dtype=np.float32)\n",
    "\n",
    "# placeholder\n",
    "# X > input layer\n",
    "X = tf.placeholder(shape=[None,2], dtype=tf.float32)\n",
    "T = tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
    "\n",
    "# W & b 1\n",
    "W1 = tf.Variable(tf.random.normal([2,10]))\n",
    "b1 = tf.Variable(tf.random.normal([10]))\n",
    "# 첫번째 Hidden layer > 여기서 출력되는 값이 다음 layer의 입력값\n",
    "layer2 =  tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "# W & b 2\n",
    "W2 = tf.Variable(tf.random.normal([10,6]))\n",
    "b2 = tf.Variable(tf.random.normal([6]))\n",
    "# 두번째 Hidden layer \n",
    "layer3 =  tf.sigmoid(tf.matmul(layer2, W2) + b2)\n",
    "\n",
    "# W & b 3\n",
    "W3 = tf.Variable(tf.random.normal([6,1]))\n",
    "b3 = tf.Variable(tf.random.normal([1]))\n",
    "\n",
    "# Hypothesis\n",
    "# 세번째 Hidden layer \n",
    "logit = tf.matmul(layer3, W3) + b3\n",
    "# output layer\n",
    "H =  tf.sigmoid(logit)\n",
    "\n",
    "# loss\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit, \n",
    "                                                           labels=T))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-2).minimize(loss)\n",
    "\n",
    "# session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning\n",
    "for step in range(30000):\n",
    "    _, loss_val = sess.run([train, loss], feed_dict={X: x_data, T: t_data})\n",
    "    \n",
    "    if step % 3000 == 0:\n",
    "        print('loss : {}'.format(loss_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tf.cast(H >= 0.5, dtype=tf.float32)\n",
    "result = sess.run(accuracy, feed_dict={X: x_data})\n",
    "\n",
    "print(classification_report(t_data.ravel(), result.ravel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow 2.x XOR Gate 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data Set\n",
    "x_data = np.array([[0,0], [0,1], [1,0], [1,1]], dtype=np.float32)\n",
    "t_data = np.array([[0], [1], [1], [0]], dtype=np.float32)\n",
    "\n",
    "# model 구현\n",
    "model = Sequential()\n",
    "\n",
    "# layer 추가\n",
    "model.add(Flatten(input_shape=(2,)))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "# compile\n",
    "model.compile(optimizer=SGD(learning_rate=1e-2), \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "# learning\n",
    "history = model.fit(x_data, t_data, epochs=1000, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002D994411558> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         2\n",
      "         1.0       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "predict_val = model.predict(x_data)\n",
    "result= tf.cast(predict_val >=0.5, dtype=tf.float32).numpy().ravel()\n",
    "print(classification_report(t_data.ravel(), result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "\n",
    "plt.plot(history.history['accuracy'], color='r')\n",
    "plt.plot(history.history['loss'], color='b')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_env_tf2]",
   "language": "python",
   "name": "conda-env-data_env_tf2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
