{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepting-wales",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-channel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data loading\n",
    "# 이미지 - 배열 변환후 csv로 출력\n",
    "for n in range(5):\n",
    "    print(n)\n",
    "    df = list()\n",
    "    for i in range(n*1250, (n+1)*1250):\n",
    "        # data loading & resize\n",
    "        dog_img = Image.open(f'../data/dogs-vs-cats/train/dog.{i}.jpg').resize((200,200))\n",
    "        cat_img = Image.open(f'../data/dogs-vs-cats/train/cat.{i}.jpg').resize((200,200))\n",
    "\n",
    "        # 흑백변환\n",
    "        dog_img = np.mean(dog_img, axis=2, keepdims=True, dtype=np.int32).astype(np.float32)\n",
    "        cat_img = np.mean(cat_img, axis=2, keepdims=True, dtype=np.int32).astype(np.float32)\n",
    "\n",
    "        df.append([1] + dog_img.ravel().tolist())\n",
    "        df.append([0] + cat_img.ravel().tolist())\n",
    "\n",
    "    df = pd.DataFrame(df)\n",
    "    df.to_csv(f'../data/dogs-vs-cats/batch{n}.csv', index=False)\n",
    "    del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-hungary",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu',\n",
    "                 input_shape=(200,200,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), activation='relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-static",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning\n",
    "model.compile(optimizer=Adam(learning_rate=1e-2), \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "history_list = list()\n",
    "for n in range(5):\n",
    "    # data load\n",
    "    df = pd.read_csv(f'../data/dogs-vs-cats/batch{n}.csv').values\n",
    "    \n",
    "    # x, t data split\n",
    "    x_data = df[:,1:]\n",
    "    t_data = df[:,0].reshape(-1,1).copy()\n",
    "    del df\n",
    "    \n",
    "    # normalization\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(x_data)\n",
    "    x_data_norm=scaler.transform(x_data)\n",
    "    del x_data\n",
    "    \n",
    "    history_list.append(model.fit(x_data_norm.reshape(-1, 200, 200, 1), t_data, \n",
    "                        epochs=20, verbose=1, validation_split=0.3))\n",
    "    del x_data_norm\n",
    "    del t_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "innovative-envelope",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "# 일부 이미지 분리(총 4000개)\n",
    "\n",
    "import os, shutil\n",
    "\n",
    "original_dataset_dir = '../data/dogs-vs-cats/train'\n",
    "\n",
    "## directory 생성 ##\n",
    "\n",
    "base_dir = '../data/cat_dog_small'\n",
    "os.mkdir(base_dir)\n",
    "\n",
    "train_dir = os.path.join(base_dir,'train')\n",
    "os.mkdir(train_dir)\n",
    "validation_dir = os.path.join(base_dir,'validation')\n",
    "os.mkdir(validation_dir)\n",
    "test_dir = os.path.join(base_dir,'test')\n",
    "os.mkdir(test_dir)\n",
    "\n",
    "train_cats_dir = os.path.join(train_dir,'cats')\n",
    "os.mkdir(train_cats_dir)\n",
    "train_dogs_dir = os.path.join(train_dir,'dogs')\n",
    "os.mkdir(train_dogs_dir)\n",
    "\n",
    "validation_cats_dir = os.path.join(validation_dir,'cats')\n",
    "os.mkdir(validation_cats_dir)\n",
    "validation_dogs_dir = os.path.join(validation_dir,'dogs')\n",
    "os.mkdir(validation_dogs_dir)\n",
    "\n",
    "test_cats_dir = os.path.join(test_dir,'cats')\n",
    "os.mkdir(test_cats_dir)\n",
    "test_dogs_dir = os.path.join(test_dir,'dogs')\n",
    "os.mkdir(test_dogs_dir)\n",
    "\n",
    "## file 복사 ##\n",
    "\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir,fname)\n",
    "    dst = os.path.join(train_cats_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1000,1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir,fname)\n",
    "    dst = os.path.join(validation_cats_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "    \n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1500,2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir,fname)\n",
    "    dst = os.path.join(test_cats_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "    \n",
    "\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir,fname)\n",
    "    dst = os.path.join(train_dogs_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000,1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir,fname)\n",
    "    dst = os.path.join(validation_dogs_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "    \n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1500,2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir,fname)\n",
    "    dst = os.path.join(test_dogs_dir, fname)\n",
    "    shutil.copyfile(src,dst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_env_tf2] *",
   "language": "python",
   "name": "conda-env-data_env_tf2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
