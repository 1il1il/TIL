{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # 텐서플로가 첫 번째 GPU에 1GB 메모리만 할당하도록 제한\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*6)])\n",
    "  except RuntimeError as e:\n",
    "    # 프로그램 시작시에 가상 장치가 설정되어야만 합니다\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15986 images belonging to 7 classes.\n",
      "Found 3992 images belonging to 7 classes.\n",
      "Found 2074 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "base_dir = '../data/telemoji/pre'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1/255,    \n",
    "#        rotation_range=40,\n",
    "#        width_shift_range=0.1,\n",
    "#        height_shift_range=0.1,\n",
    "#        zoom_range=0.2,\n",
    "#        horizontal_flip=True,\n",
    "#        vertical_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "     rescale=1/255\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir, \n",
    "    color_mode='grayscale',\n",
    "    target_size=(48,48),\n",
    "    batch_size=20,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    color_mode='grayscale',\n",
    "    target_size=(150,150),\n",
    "    batch_size=20,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    color_mode='grayscale',\n",
    "    target_size=(150,150),\n",
    "    batch_size=20,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensroflow 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tensorflow.python.framework.ops.EagerTensor' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-8bad274826a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;31m### train ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRMSprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m     \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategorical_crossentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlable_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFC5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlable_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFC5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data_env_tf2\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(self, loss, var_list, grad_loss, name)\u001b[0m\n\u001b[0;32m    373\u001b[0m     \"\"\"\n\u001b[0;32m    374\u001b[0m     grads_and_vars = self._compute_gradients(\n\u001b[1;32m--> 375\u001b[1;33m         loss, var_list=var_list, grad_loss=grad_loss)\n\u001b[0m\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data_env_tf2\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36m_compute_gradients\u001b[1;34m(self, loss, var_list, grad_loss)\u001b[0m\n\u001b[0;32m    427\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m         \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m       \u001b[0mloss_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m       \u001b[0mvar_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object is not callable"
     ]
    }
   ],
   "source": [
    "for data_batch, lable_batch in train_generator:\n",
    "    ### block 1 ###\n",
    "    C1 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same')(data_batch)\n",
    "    C2 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same')(C1)\n",
    "\n",
    "    P1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='valid')(C2)\n",
    "    P1 = tf.keras.activations.relu(P1)\n",
    "\n",
    "    ### block 2 ###\n",
    "    C3 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same')(P1)\n",
    "    C4 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same')(C3)\n",
    "    C5 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same')(C4)\n",
    "\n",
    "    P2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='valid')(C5)\n",
    "    P2 = tf.keras.activations.relu(P2)\n",
    "\n",
    "    FC1 = tf.keras.layers.Flatten()(P2)\n",
    "    FC1 = tf.keras.layers.Dense(256)(FC1)\n",
    "\n",
    "    ### block 3 ###\n",
    "    C6 = tf.keras.layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same')(P2)\n",
    "    C7 = tf.keras.layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same')(C6)\n",
    "    C8 = tf.keras.layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same')(C7)\n",
    "    C9 = tf.keras.layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same')(C8)\n",
    "\n",
    "    P3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='valid')(C9)\n",
    "    P3 = tf.keras.activations.relu(P3)\n",
    "\n",
    "    FC2 = tf.keras.layers.Flatten()(P3)\n",
    "    FC2 = tf.keras.layers.Dense(256)(FC2)\n",
    "\n",
    "    ### block 4 ###\n",
    "    C10 = tf.keras.layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same')(P3)\n",
    "    C11 = tf.keras.layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same')(C10)\n",
    "    C12 = tf.keras.layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same')(C11)\n",
    "    C13 = tf.keras.layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same')(C12)\n",
    "\n",
    "    P4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='valid')(C13)\n",
    "    P4 = tf.keras.activations.relu(P4)\n",
    "\n",
    "    FC3 = tf.keras.layers.Flatten()(P4)\n",
    "    FC3 = tf.keras.layers.Dense(256)(FC3)\n",
    "\n",
    "    ### block 5 ###\n",
    "    C14 = tf.keras.layers.Conv2D(filters=512, kernel_size=3, activation='relu', padding='same')(P4)\n",
    "    C15 = tf.keras.layers.Conv2D(filters=512, kernel_size=3, activation='relu', padding='same')(C14)\n",
    "    C16 = tf.keras.layers.Conv2D(filters=512, kernel_size=3, activation='relu', padding='same')(C15)\n",
    "    C17 = tf.keras.layers.Conv2D(filters=512, kernel_size=3, activation='relu', padding='same')(C16)\n",
    "\n",
    "    P5 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='valid')(C17)\n",
    "    P5 = tf.keras.activations.relu(P5)\n",
    "    \n",
    "    FC4 = tf.keras.layers.Flatten()(P5)\n",
    "\n",
    "    FC5 = tf.concat([FC1, FC2, FC3, FC4], 1)\n",
    "    FC5 = tf.keras.layers.Dense(7, activation='softmax')(FC4)\n",
    "\n",
    "    ### loss function ###\n",
    "    loss = tf.keras.losses.categorical_crossentropy(lable_batch, FC5)\n",
    "\n",
    "    ### train ###\n",
    "    opt = tf.keras.optimizers.RMSprop(learning_rate=1e-4)\n",
    "    train = opt.minimize(loss, [FC5])\n",
    "    break\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### block 1 ###\n",
    "C1 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same')()\n",
    "C2 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same')(C1)\n",
    "\n",
    "P1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='valid')(C2)\n",
    "P1 = tf.keras.activations.relu(P1)\n",
    "\n",
    "### block 2 ###\n",
    "C3 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same')(P1)\n",
    "C4 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same')(C3)\n",
    "C5 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same')(C4)\n",
    "\n",
    "P2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='valid')(C5)\n",
    "P2 = tf.keras.activations.relu(P2)\n",
    "\n",
    "FC1 = tf.keras.layers.Flatten()(P2)\n",
    "FC1 = tf.keras.layers.Dense(256)(FC1)\n",
    "\n",
    "### block 3 ###\n",
    "C6 = tf.keras.layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same')(P2)\n",
    "C7 = tf.keras.layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same')(C6)\n",
    "C8 = tf.keras.layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same')(C7)\n",
    "C9 = tf.keras.layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same')(C8)\n",
    "\n",
    "P3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='valid')(C9)\n",
    "P3 = tf.keras.activations.relu(P3)\n",
    "\n",
    "FC2 = tf.keras.layers.Flatten()(P3)\n",
    "FC2 = tf.keras.layers.Dense(256)(FC2)\n",
    "\n",
    "### block 4 ###\n",
    "C10 = tf.keras.layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same')(P3)\n",
    "C11 = tf.keras.layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same')(C10)\n",
    "C12 = tf.keras.layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same')(C11)\n",
    "C13 = tf.keras.layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same')(C12)\n",
    "\n",
    "P4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='valid')(C13)\n",
    "P4 = tf.keras.activations.relu(P4)\n",
    "\n",
    "FC3 = tf.keras.layers.Flatten()(P4)\n",
    "FC3 = tf.keras.layers.Dense(256)(FC3)\n",
    "\n",
    "### block 5 ###\n",
    "C14 = tf.keras.layers.Conv2D(filters=512, kernel_size=3, activation='relu', padding='same')(P4)\n",
    "C15 = tf.keras.layers.Conv2D(filters=512, kernel_size=3, activation='relu', padding='same')(C14)\n",
    "C16 = tf.keras.layers.Conv2D(filters=512, kernel_size=3, activation='relu', padding='same')(C15)\n",
    "C17 = tf.keras.layers.Conv2D(filters=512, kernel_size=3, activation='relu', padding='same')(C16)\n",
    "\n",
    "P5 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='valid')(C17)\n",
    "P5 = tf.keras.activations.relu(P5)\n",
    "\n",
    "FC4 = tf.concat([FC1, FC2, FC3, P5])\n",
    "FC4 = tf.keras.layers.Dense(7, activation='softmax')(FC4)\n",
    "\n",
    "### loss function ###\n",
    "loss = tf.keras.losses.categorical_crossentropy(y_true, FC4)\n",
    "\n",
    "### train ###\n",
    "opt = tf.keras.optimizers.RMSprop(learning_rate=1e-4)\n",
    "train = opt.minimize(loss, [FC4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_env_tf2]",
   "language": "python",
   "name": "conda-env-data_env_tf2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
