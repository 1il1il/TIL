{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "later-constitutional",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czech-disability",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data loading\n",
    "# 이미지 - 배열 변환후 csv로 출력\n",
    "for n in range(10):\n",
    "    print(n)\n",
    "    df = list()\n",
    "    for i in range(n*625, (n+1)*625):\n",
    "        # data loading & resize\n",
    "        dog_img = Image.open(f'../data/dogs-vs-cats/train/dog.{i}.jpg').resize((150,150))\n",
    "        cat_img = Image.open(f'../data/dogs-vs-cats/train/cat.{i}.jpg').resize((150,150))\n",
    "\n",
    "        # 흑백변환\n",
    "        dog_img = np.mean(dog_img, axis=2, keepdims=True, dtype=np.int32).astype(np.float32)\n",
    "        cat_img = np.mean(cat_img, axis=2, keepdims=True, dtype=np.int32).astype(np.float32)\n",
    "\n",
    "        df.append([1] + dog_img.ravel().tolist())\n",
    "        df.append([0] + cat_img.ravel().tolist())\n",
    "\n",
    "    df = pd.DataFrame(df)\n",
    "    df.to_csv(f'../data/dogs-vs-cats/batch{n}.csv', index=False)\n",
    "    del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dynamic-tourist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 150, 150, 32)      320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 75, 75, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 37, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 37, 37, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 18, 18, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 10368)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               5308928   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 5,549,697\n",
      "Trainable params: 5,549,697\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), \n",
    "                 activation='relu', input_shape=(150,150,1), padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), \n",
    "                 activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), \n",
    "                 activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), \n",
    "                 activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=512, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "smart-output",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번째 학습 시작\n",
      "1번째 학습 종료\n",
      "2번째 학습 시작\n",
      "2번째 학습 종료\n",
      "3번째 학습 시작\n",
      "3번째 학습 종료\n",
      "4번째 학습 시작\n",
      "4번째 학습 종료\n",
      "5번째 학습 시작\n",
      "5번째 학습 종료\n",
      "6번째 학습 시작\n",
      "6번째 학습 종료\n",
      "7번째 학습 시작\n",
      "7번째 학습 종료\n",
      "8번째 학습 시작\n",
      "8번째 학습 종료\n",
      "9번째 학습 시작\n",
      "9번째 학습 종료\n",
      "10번째 학습 시작\n",
      "10번째 학습 종료\n"
     ]
    }
   ],
   "source": [
    "# learning\n",
    "model.compile(optimizer=Adam(learning_rate=1e-3), \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_list = list()\n",
    "for n in range(10):\n",
    "    # data load\n",
    "    df = pd.read_csv(f'../data/dogs-vs-cats/batch{n}.csv')\n",
    "    # data shuffle\n",
    "    df = df.sample(frac=1).reset_index(drop=True).values\n",
    "    \n",
    "    # x, t data split\n",
    "    x_data = df[:,1:].copy()\n",
    "    t_data = df[:,0].copy()\n",
    "    del df\n",
    "    \n",
    "    # normalization\n",
    "    x_data = x_data % 255\n",
    "    \n",
    "    # reshape\n",
    "    x_data = x_data.reshape(-1, 150, 150, 1)\n",
    "    \n",
    "    print(f'{n+1}번째 학습 시작')\n",
    "    history_list.append(model.fit(x_data, t_data, \n",
    "                        epochs=30, verbose=0, validation_split=0.3))\n",
    "    print(f'{n+1}번째 학습 종료')\n",
    "    del x_data\n",
    "    del t_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "agreed-murder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9085333307584127\n",
      "0.5736000001430511\n",
      "0.8858666698137919\n",
      "0.7466285745302836\n",
      "0.8937523821989696\n",
      "0.8470476170380911\n",
      "0.904152375459671\n",
      "0.8520380934079488\n",
      "0.8661714295546213\n",
      "0.9244571407636006\n",
      "Total Accuracy : 0.8402247613668443\n"
     ]
    }
   ],
   "source": [
    "acc_list = list()\n",
    "for history in history_list:\n",
    "    acc = np.mean(history.history['accuracy'])\n",
    "    print(acc)\n",
    "    acc_list.append(acc)\n",
    "\n",
    "print(f'Total Accuracy : {np.mean(acc_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "removable-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data shuffle test\n",
    "\n",
    "df = pd.read_csv('../data/dogs-vs-cats/batch0.csv')\n",
    "df = df.sample(frac=1).reset_index(drop=True).values\n",
    "\n",
    "# x, t data split\n",
    "x_data = df[:,1:].copy()\n",
    "t_data = df[:,0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-gathering",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset\n",
    "# 일부 이미지 분리(총 4000개)\n",
    "\n",
    "import os, shutil\n",
    "\n",
    "original_dataset_dir = '../data/dogs-vs-cats/train'\n",
    "\n",
    "## directory 생성 ##\n",
    "\n",
    "base_dir = '../data/cat_dog_small'\n",
    "os.mkdir(base_dir)\n",
    "\n",
    "train_dir = os.path.join(base_dir,'train')\n",
    "os.mkdir(train_dir)\n",
    "validation_dir = os.path.join(base_dir,'validation')\n",
    "os.mkdir(validation_dir)\n",
    "test_dir = os.path.join(base_dir,'test')\n",
    "os.mkdir(test_dir)\n",
    "\n",
    "train_cats_dir = os.path.join(train_dir,'cats')\n",
    "os.mkdir(train_cats_dir)\n",
    "train_dogs_dir = os.path.join(train_dir,'dogs')\n",
    "os.mkdir(train_dogs_dir)\n",
    "\n",
    "validation_cats_dir = os.path.join(validation_dir,'cats')\n",
    "os.mkdir(validation_cats_dir)\n",
    "validation_dogs_dir = os.path.join(validation_dir,'dogs')\n",
    "os.mkdir(validation_dogs_dir)\n",
    "\n",
    "test_cats_dir = os.path.join(test_dir,'cats')\n",
    "os.mkdir(test_cats_dir)\n",
    "test_dogs_dir = os.path.join(test_dir,'dogs')\n",
    "os.mkdir(test_dogs_dir)\n",
    "\n",
    "## file 복사 ##\n",
    "\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir,fname)\n",
    "    dst = os.path.join(train_cats_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1000,1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir,fname)\n",
    "    dst = os.path.join(validation_cats_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "    \n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1500,2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir,fname)\n",
    "    dst = os.path.join(test_cats_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "    \n",
    "\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir,fname)\n",
    "    dst = os.path.join(train_dogs_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000,1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir,fname)\n",
    "    dst = os.path.join(validation_dogs_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "    \n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1500,2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir,fname)\n",
    "    dst = os.path.join(test_dogs_dir, fname)\n",
    "    shutil.copyfile(src,dst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_env_tf2] *",
   "language": "python",
   "name": "conda-env-data_env_tf2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
